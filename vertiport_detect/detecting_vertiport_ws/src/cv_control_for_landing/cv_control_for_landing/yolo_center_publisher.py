import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from sensor_msgs.msg import CameraInfo
from sensor_msgs.msg import PointCloud2
from geometry_msgs.msg import Point
from cv_bridge import CvBridge
import cv2
import numpy as np
from ultralytics import YOLO


class YOLOCenterPublisher(Node):
    def __init__(self):
        super().__init__('yolo_center_publisher')

        # YOLO ëª¨ë¸ ë¡œë“œ
        model_path = '/home/haechan/Repo_2025/machine_AI/vertiport_detect/training_yolo/runs/detect/train9/weights/best.pt'
        self.model = YOLO(model_path)

        # ì¹´ë©”ë¼ í† í”½ êµ¬ë…
        self.subscription = self.create_subscription(
            Image,
            '/camera/realsense_front/color/image_raw',
            self.image_callback,
            10
        )

        # ê¹Šì´ ì´ë¯¸ì§€ êµ¬ë… (depth aligned to color)
        self.depth_sub = self.create_subscription(
            Image,
           '/camera/realsense_front/depth/image_rect_raw',
            self.depth_callback,
            10
        )

        # ê¹Šì´ í”„ë ˆì„ ì €ì¥ìš©
        self.latest_depth_image = None

        # ì¤‘ì‹¬ ì¢Œí‘œ í¼ë¸”ë¦¬ì…”
        self.publisher = self.create_publisher(Point, '/yolo_center', 10)

        self.bridge = CvBridge()
        self.get_logger().info("ğŸš€ YOLO ë¼ë²¨ + ê¹Šì´ ì¢Œí‘œ í¼ë¸”ë¦¬ì…” ë…¸ë“œ ì‹œì‘!")

    def depth_callback(self, msg):
        # ìµœì‹  depth ì´ë¯¸ì§€ ì €ì¥ (ë‹¨ìœ„: mm â†’ m ë³€í™˜ í•„ìš” ì‹œ ì—¬ê¸°ì„œ ì²˜ë¦¬)
        self.latest_depth_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')

    def image_callback(self, msg):
        if self.latest_depth_image is None:
            self.get_logger().warn("ì•„ì§ depth í”„ë ˆì„ ì—†ìŒ. ëŒ€ê¸° ì¤‘...")
            return

        frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
        results = self.model(frame)[0]

        for box in results.boxes:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            cls_id = int(box.cls[0].item())
            cls_name = self.model.names[cls_id]

            # ì¤‘ì‹¬ ì¢Œí‘œ ê³„ì‚°
            cx = int((x1 + x2) / 2)
            cy = int((y1 + y2) / 2)

            # ì¤‘ì‹¬ ì¢Œí‘œì— í•´ë‹¹í•˜ëŠ” ê¹Šì´ ê°’ ê°€ì ¸ì˜¤ê¸°
            if 0 <= cy < self.latest_depth_image.shape[0] and 0 <= cx < self.latest_depth_image.shape[1]:
                depth_value = self.latest_depth_image[cy, cx]  # mm ë‹¨ìœ„
                depth_in_m = float(depth_value) / 1000.0  # m ë‹¨ìœ„ë¡œ ë³€í™˜
            else:
                depth_in_m = 0.0

            # ROS ë©”ì‹œì§€ë¡œ í¼ë¸”ë¦¬ì‹œ
            point = Point()
            point.x = float(cx)
            point.y = float(cy)
            point.z = depth_in_m
            self.publisher.publish(point)

            # ì¶œë ¥
            self.get_logger().info(f"ğŸ¯ ê°ì²´: {cls_name} | ì¤‘ì‹¬: ({cx}, {cy}) | ê¹Šì´: {depth_in_m:.2f} m")

        # ì‹œê°í™”
        annotated = results.plot()
        cv2.imshow("YOLOv8 Detection with Depth", annotated)
        cv2.waitKey(1)


def main(args=None):
    rclpy.init(args=args)
    node = YOLOCenterPublisher()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        print("ğŸ›‘ ì¢…ë£Œë¨.")
    finally:
        node.destroy_node()
        rclpy.shutdown()
        cv2.destroyAllWindows()
